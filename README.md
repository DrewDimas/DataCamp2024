# Data Engineering Zoomcamp Portfolio

This repository serves as a portfolio for my journey through the Data Engineering Zoomcamp, hosted by DataTalks.Club. Throughout this comprehensive course, I have gained hands-on experience and in-depth knowledge in various cutting-edge technologies and methodologies pivotal to the data engineering landscape.

## Key Learnings & Technologies

During the Zoomcamp, I focused on mastering the following technologies and concepts, which are essential for modern data engineers:

- **Google Cloud Platform (GCP):** Explored cloud-based auto-scaling platforms by Google, leveraging various services for scalable, robust data engineering pipelines.
- **Google Cloud Storage (GCS):** Utilized as a Data Lake for storing vast amounts of structured and unstructured data.
- **BigQuery:** Mastered using BigQuery as a highly scalable, cost-effective Data Warehouse for analytics and data querying at scale.
- **Terraform:** Applied Infrastructure-as-Code (IaC) practices with Terraform to provision and manage cloud infrastructure declaratively.
- **Docker:** Gained proficiency in containerization with Docker, enabling consistent deployment and isolation of applications across environments.
- **SQL:** Enhanced data analysis and exploration skills using SQL, the cornerstone for interacting with relational databases.
- **Mage:** Implemented workflow orchestration with Mage to automate and manage complex data pipelines.
- **dbt (data build tool):** Leveraged dbt for data transformation, enabling clean, testable, and manageable data transformation layers.
- **Apache Spark:** Dived into distributed processing with Spark, learning to process large datasets efficiently across clustered environments.
- **Apache Kafka:** Explored streaming data processing with Kafka, understanding the principles of real-time data ingestion, processing, and distribution.

## Course Structure

The Zoomcamp was structured into six modules, each focusing on a critical area of data engineering, complemented by workshops and a capstone project:

1. **Containerization and Infrastructure as Code**
2. **Workflow Orchestration**
3. **Data Warehouse**
4. **Analytics Engineering**
5. **Batch Processing**
6. **Streaming**

### Workshops

- **Data Ingestion**
- **Stream Processing with SQL**

<!-- ### Capstone Project

The culmination of the course was a comprehensive project that required the application of all the skills and technologies learned throughout the modules. This project provided a practical, hands-on experience in designing, building, and deploying a scalable data engineering pipeline. -->

## Personal Achievements

Throughout this course, I have:

- Completed multiple hands-on projects and exercises.
- Developed a deep understanding of both theoretical concepts and practical applications in data engineering.
- Built a portfolio demonstrating my capabilities in handling real-world data engineering challenges.

## Future Goals

Armed with the knowledge and experience gained from the Data Engineering Zoomcamp, I am excited to explore further and apply these skills in solving complex data problems in various domains.

---

This repository is a testament to my dedication and hard work in completing the Data Engineering Zoomcamp. It reflects my commitment to continuous learning and my passion for data engineering.

Thank you for visiting my portfolio. Feel free to explore my projects and reach out if you have any questions or collaboration ideas.
 
 